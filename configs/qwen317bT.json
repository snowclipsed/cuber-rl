{
  "wandb_project": "cuber-rl",
  "wandb_name": "qwen3-1.7b-thinking-lora-peft",
  "model_name": "willcb/Qwen3-1.7B",
  "env_name": "cuber-rl",
  "difficulties": ["very_easy"],
  "max_moves_per_turn": 1,
  "max_episode_steps": 3,
  "run_name": "rubiks-cube-grpo-qwen1.7b",
  "output_model_path": "./final_rubiks_model",
  "training_args": {
    "per_device_train_batch_size": 4,
    "num_generations": 8,
    "gradient_accumulation_steps": 4,
    "max_tokens": 4096,
    "max_seq_len": 6144,
    "max_steps": 100,
    "eval_strategy": "steps",
    "eval_steps": 2,
    "save_steps": 10,
    "logging_steps": 1,
    "mask_env_responses": true,
    "max_grad_norm": 0.25,
    "beta": 0.0,
    "async_generation_timeout": 600,
    "learning_rate": 1e-5,
    "warmup_ratio": 0.1,
    "fp16": true,
    "gradient_checkpointing": true,
    "output_dir": "./rubiks_cube_checkpoints",
    "report_to": "wandb"
  }
}